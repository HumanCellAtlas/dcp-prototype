#!/usr/bin/env python3
import subprocess
import json
import os
import time
from datetime import datetime

import boto3
from botocore.config import Config
import click


class DevEnvDataStore:
    def __init__(self, ctx):
        self.ctx = ctx
        self.secret_id = "happy/rdev-tracker"
        self.aws_conf = ctx.obj["aws_conf"]
        self.secret_client = boto3.client("secretsmanager", config=self.aws_conf)
        self.envs = {}
        self.envs_loaded = False

    def get_envs(self):
        if self.envs_loaded:
            return self.envs
        secret = json.loads(self.secret_client.get_secret_value(SecretId=self.secret_id)["SecretString"])
        self.envs = secret
        self.envs_loaded = True
        return self.envs

    def write_envs(self):
        envs = self.get_envs()
        secret = self.secret_client.put_secret_value(SecretId=self.secret_id, SecretString=json.dumps(envs))
        return True

    def delete_env(self, env_name):
        envs = self.get_envs()
        del envs[env_name]
        self.envs = envs
        self.write_envs()

    def update_env(self, env_name, document):
        envs = self.get_envs()
        envs[env_name] = document
        self.envs = envs
        self.write_envs()

    def get_env(self, env_name):
        envs = self.get_envs()
        return envs[env_name]

    def get_owner(self):
        # Figure out what our current identity is
        sts_client = boto3.client("sts", config=self.aws_conf)
        identity = sts_client.get_caller_identity()["Arn"]
        return identity.split("/")[-1]

    def create_env(self, env_name):
        envs = self.get_envs()
        if env_name in envs:
            raise Exception("Env already exists")

        # Find the first available priority id and use it.
        existing_priorities = set()
        slots = set(range(1, len(envs) + 1))
        priority = len(envs) + 1
        for env in envs.values():
            existing_priorities.add(env["priority"])
        free_slots = slots - existing_priorities
        if len(free_slots):
            priority = min(free_slots)

        # Track a creation date for this stack.
        now = time.time()
        # Save
        env_info = {
            "priority": priority,
            "owner": self.get_owner(),
            "created_at": now,
        }
        self.update_env(env_name, env_info)
        self.write_envs()
        return env_info


@click.group()
@click.option("--profile", default="single-cell-dev", help="AWS profile to use")
@click.pass_context
def cli(ctx, profile):
    ctx.ensure_object(dict)
    ctx.obj["aws_profile"] = profile
    os.environ["AWS_PROFILE"] = profile  # Lame hack. Need to make this smarter.
    aws_conf = Config(region_name="us-west-2", retries={"max_attempts": 2, "mode": "standard"})
    client = boto3.client("cloudformation", config=aws_conf)
    ctx.obj["client"] = client
    ctx.obj["aws_conf"] = aws_conf


def get_secrets(ctx):
    output = run_aws_cmd(ctx, ["secretsmanager", "get-secret-value", "--secret-id", "happy/dp-rdev-config"])
    secrets = json.loads(output["SecretString"])
    return secrets


def run_aws_cmd(ctx, cmd, return_output=True, json_output=True):
    command = ["aws", "--profile", ctx.obj["aws_profile"], "--region", "us-west-2"]
    command.extend(cmd)
    if return_output:
        output = subprocess.check_output(command)
    else:
        subprocess.check_call(command)
        return
    if not json_output:
        return output
    return json.loads(output)


def get_stack(ctx, label):
    status_cmd = [
        "aws",
        "cloudformation",
        "describe-stacks",
        "--profile",
        ctx.obj["aws_profile"],
        "--stack-name",
        label,
    ]
    stack = json.loads(subprocess.check_output(status_cmd))["Stacks"][0]
    return stack


def get_outputs(ctx, label=None, stack=None):
    if not stack:
        stack = get_stack(ctx, label)
    outputs = {}
    for op in stack.get("Outputs", []):
        outputs[op["OutputKey"]] = op["OutputValue"]
    return outputs


def print_outputs(ctx, label=None, stack=None):
    outputs = get_outputs(ctx, label, stack)
    if not outputs:
        return
    print()
    print("Module Outputs --")
    for k, v in outputs.items():
        print(f"{k}: {v}")


def get_migration_taskdef(ctx, label):
    """Find the migration task definition in our CF stack"""
    path = ["DevEnv", "DevEnv", "MigrateDB", "TaskDefinition"]
    arn = label
    path_length = len(path)
    for i in range(path_length):
        cmd = [
            "aws",
            "cloudformation",
            "describe-stack-resources",
            "--profile",
            ctx.obj["aws_profile"],
            "--stack-name",
            arn,
        ]
        resources = json.loads(subprocess.check_output(cmd))["StackResources"]
        # Convert to a map of CloudFormation object name => AWS resource ARN
        resource_map = {item["LogicalResourceId"]: {"arn": item["PhysicalResourceId"], "status": item["ResourceStatus"], "stack_name": item["StackName"]} for item in resources}
        resource = resource_map[path[i]]
        arn = resource["arn"]
    return resource


@cli.command()
@click.argument("label")
@click.pass_context
def migrate(ctx, label):
    """Run DB migration task in dev account"""
    secrets = get_secrets(ctx)
    cluster_arn = secrets["cluster_arn"]
    subnets = secrets["subnets"]
    security_groups = secrets["security_groups"]
    return _migrate(ctx, label, cluster_arn, subnets, security_groups)


def _migrate(ctx, label, cluster_arn, subnets, security_groups):
    """Run DB migration task"""
    taskdef_arn = get_migration_taskdef(ctx, label)["arn"]
    print(f"Using task definition {taskdef_arn}")
    command = [
        "aws",
        "ecs",
        "run-task",
        "--profile",
        ctx.obj["aws_profile"],
        "--cluster",
        cluster_arn,
        "--task-definition",
        taskdef_arn,
        "--network-configuration",
        f"awsvpcConfiguration={{subnets=[{subnets}],securityGroups=[{security_groups}],assignPublicIp='DISABLED'}}",
    ]
    task_info = json.loads(subprocess.check_output(command))["tasks"][0]
    print(f"Task {task_info['taskArn']} started")
    # Wait for the task to exit.
    status_cmd = [
        "aws",
        "ecs",
        "describe-tasks",
        "--tasks",
        task_info["taskArn"],
        "--profile",
        ctx.obj["aws_profile"],
        "--cluster",
        cluster_arn,
    ]
    log_stream = ""
    while True:
        taskinfo = json.loads(subprocess.check_output(status_cmd))["tasks"][0]
        try:
            status = taskinfo["containers"][0]["lastStatus"]
            reason = ""
            if reason in taskinfo["containers"][0]:
                reason = taskinfo["containers"][0]["reason"]
                print(f"{status}: {reason}")
            log_stream = taskinfo["containers"][0]["runtimeId"]
            if status == "STOPPED":
                break
        except:
            print("Container hasn't started yet")
    # Get logs
    print("getting taskdef info")
    taskdef_cmd = [
        "aws",
        "ecs",
        "describe-task-definition",
        "--profile",
        ctx.obj["aws_profile"],
        "--task-definition",
        taskdef_arn,
    ]
    taskdef = json.loads(subprocess.check_output(taskdef_cmd))["taskDefinition"]
    log_group = taskdef["containerDefinitions"][0]["logConfiguration"]["options"]["awslogs-group"]
    print("Log Events:")
    log_cmd = [
        "aws",
        "logs",
        "get-log-events",
        "--log-group-name",
        log_group,
        "--log-stream-name",
        log_stream,
        "--profile",
        ctx.obj["aws_profile"],
    ]
    logs = json.loads(subprocess.check_output(log_cmd))["events"]
    for log in logs:
        print(log)
    print("done!")


def invoke_wait(ctx, label):
    last_status = ""
    while True:
        stack = get_stack(ctx, label)
        status = stack["StackStatus"]
        if status != last_status:
            print(f"{datetime.now().strftime('%H:%M:%S')} - {status}")
            last_status = status
        if status.endswith("IN_PROGRESS"):
            time.sleep(2)
        else:
            # We're done.
            print_outputs(ctx, stack=stack)
            return stack


@cli.command()
@click.argument("label")
@click.argument("service")
@click.option("--since", default="10m", help="Output logs since <number>s|m|h|d")
@click.pass_context
def logs(ctx, label, service, since):
    """Tail the logs of a service (frontend or backend)"""
    run_aws_cmd(
        ctx,
        ["logs", "tail", "--since", since, "--follow", f"{label}/{service}"],
        return_output=False,
        json_output=False,
    )

    
def wait_for_migration_update(ctx, label):
    """Wait for the migration task update to complete"""
    migration_stack_arn = get_migration_taskdef(ctx, label)["stack_name"]
    # TODO, how do we make sure the migration stack's status isn't from the *last* update????
    print(f"Waiting for migration stack to be updated: {migration_stack_arn}")
    invoke_wait(ctx, migration_stack_arn)
    print(f"Migration stack is ready")


@cli.command()
@click.argument("label")
@click.argument("tag")
@click.option("--wait/--no-wait", is_flag=True, default=True, help="wait for this to complete")
@click.pass_context
def create(ctx, label, tag, wait):
    """Create a dev stack with a given tag"""
    envdata = DevEnvDataStore(ctx)
    env = envdata.create_env(label)
    print(f"creating {label}")
    command = [
        "aws",
        "cloudformation",
        "create-stack",
        "--template-body",
        "file://scripts/remotedev.yml",
        "--profile",
        ctx.obj["aws_profile"],
        "--on-failure",
        "DO_NOTHING",
        "--stack-name",
        label,
        "--parameters",
        f"ParameterKey=Owner,ParameterValue={envdata.get_owner()}",
        f"ParameterKey=Priority,ParameterValue={env['priority']}",
        f"ParameterKey=ImageTag,ParameterValue={tag}",
    ]
    subprocess.check_call(command)
    if wait:
        stack = invoke_wait(ctx, label)

@cli.command()
@click.argument("label")
@click.argument("tag")
@click.option("--wait/--no-wait", is_flag=True, default=True, help="wait for this to complete")
@click.pass_context
def update(ctx, label, tag, wait):
    """Update a dev stack tag version"""
    print(f"updating {label}")
    envdata = DevEnvDataStore(ctx)
    env = envdata.get_env(label)
    command = [
        "aws",
        "cloudformation",
        "update-stack",
        "--template-body",
        "file://scripts/remotedev.yml",
        "--profile",
        ctx.obj["aws_profile"],
        "--stack-name",
        label,
        "--parameters",
        f"ParameterKey=Owner,ParameterValue={envdata.get_owner()}",
        f"ParameterKey=Priority,ParameterValue={env['priority']}",
        f"ParameterKey=ImageTag,ParameterValue={tag}",
    ]
    subprocess.check_call(command)
    migration_taskdef = get_migration_taskdef(ctx, label)["arn"]
    # invoke migrations
    wait_for_migration_update(ctx, label)
    ctx.invoke(migrate, label=label)
    # Wait for the rest of the stack to update.
    if wait:
        invoke_wait(ctx, label)


@cli.command()
@click.argument("label")
@click.option("--wait/--no-wait", is_flag=True, default=True, help="wait for this to complete")
@click.pass_context
def cancelupdate(ctx, label, wait):
    """Cancel a dev stack update"""
    print(f"Canceling update of {label}")
    command = [
        "aws",
        "cloudformation",
        "cancel-update-stack",
        "--profile",
        ctx.obj["aws_profile"],
        "--stack-name",
        label,
    ]
    subprocess.check_call(command)
    if wait:
        invoke_wait(ctx, label)


@cli.command()
@click.argument("label")
@click.pass_context
def delete(ctx, label):
    """Delete a dev stack"""
    print(f"deleting {label}")
    envdata = DevEnvDataStore(ctx)
    try:
        env = envdata.delete_env(label)
    except:
        print("rdev env doesn't exist in our list")
    command = [
        "aws",
        "cloudformation",
        "delete-stack",
        "--profile",
        ctx.obj["aws_profile"],
        "--stack-name",
        label,
    ]
    subprocess.check_call(command)


@cli.command()
@click.pass_context
def list(ctx):
    """List dev stacks"""
    print(f"Listing stacks")
    stacks = ctx.obj["client"].describe_stacks()
    for stack in stacks["Stacks"]:
        if stack.get("ParentId"):
            # For now, skip sub-stacks
            continue
        print(f"Stack: {stack['StackName']} / Status: {stack['StackStatus']}")


@cli.command()
@click.argument("tag")
@click.pass_context
def push(ctx, tag):
    """Build and push docker images to ECR"""
    print("Building images...")
    subprocess.check_call(["docker-compose", "build"])
    secrets = get_secrets(ctx)
    frontend_ecr = secrets["frontend_ecr"]
    backend_ecr = secrets["backend_ecr"]
    print("logging in to ECR...")
    pwd = run_aws_cmd(ctx, ["ecr", "get-login-password", "--region", "us-west-2"], json_output=False)
    login_ecr = frontend_ecr.split("/")[0]
    cmd = subprocess.run(["docker", "login", "--username", "AWS", "--password-stdin", login_ecr], input=pwd)
    print("Tagging images...")
    subprocess.check_call(["docker", "tag", "corpora-frontend:latest", f"{frontend_ecr}:{tag}"])
    subprocess.check_call(["docker", "tag", "corpora-backend:latest", f"{backend_ecr}:{tag}"])
    print("Pushing images...")
    subprocess.check_call(["docker", "push", f"{frontend_ecr}:{tag}"])
    subprocess.check_call(["docker", "push", f"{backend_ecr}:{tag}"])


@cli.command()
@click.argument("label")
@click.pass_context
def watch(ctx, label):
    """Wait until a dev stack is updated"""
    invoke_wait(ctx, label)


@cli.command()
@click.argument("label")
@click.pass_context
def status(ctx, label):
    """Get detailed status info for a dev stack"""
    print(f"checking status for {label}")
    command = [
        "aws",
        "cloudformation",
        "describe-stacks",
        "--profile",
        ctx.obj["aws_profile"],
    ]
    output = subprocess.check_output(command)
    data = json.loads(output)
    outputs = {}
    for stack in data["Stacks"]:
        stack_path = stack.get("RootId") or stack.get("StackId")
        reason = stack.get("StackStatusReason")
        # Skip any stacks that aren't part of this one.
        if f"/{label}/" not in stack_path:
            continue
        print(f"Stack: {stack['StackName']} / Status: {stack['StackStatus']} / Reason: {reason}")
        if reason:
            get_events = [
                "aws",
                "cloudformation",
                "describe-stack-events",
                "--profile",
                ctx.obj["aws_profile"],
                "--stack-name",
                stack["StackName"],
            ]
            events = subprocess.check_output(get_events)
            eventdata = json.loads(events)["StackEvents"]
            # Print most recent 3 events
            show_events = 3
            for event in eventdata:
                combo = [
                    event.get("ResourceType", ""),
                    event.get("LogicalResourceId", ""),
                    event.get("ResourceStatus", ""),
                    event.get("ResourceStatusReason", ""),
                ]
                print(" / ".join(combo))
                show_events -= 1
                if show_events <= 0:
                    break
        # Capture outputs from this stack to display to our users.
        if stack["StackName"] == label:
            outputs = get_outputs(ctx, stack=stack)
    print(outputs)


if __name__ == "__main__":
    cli()
